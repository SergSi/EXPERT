import os
import re
import json
import yaml
import chardet
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd
from datetime import datetime
import uuid
import streamlit as st

# ==============================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–ê–ü–û–ö –ò –¢–ò–ü–û–í –î–û–ö–£–ú–ï–ù–¢–û–í
# ==============================================

CONFIG = {
    "folders": {
        "normative": r"D:\YandexDisk\WORK\EXPERT\BD\NORMATIVE",      # –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ "–ì–õ–ê–í–ê"
        "methodology": r"D:\YandexDisk\WORK\EXPERT\BD\METHODOLOGY", # –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º markdown
        "structured": r"D:\YandexDisk\WORK\EXPERT\BD\STRUCTURED",   # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ - —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–º —Å–∫–æ–±–∫–∞–º
        "expertise": r"D:\YandexDisk\WORK\EXPERT\BD\EXPERTISE"      # –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ - —Ü–µ–ª–∏–∫–æ–º
    },
    "database_path": r".\knowledge_database.db",
    "templates_path": r".\templates.json"
}

# ==============================================
# –°–ò–°–¢–ï–ú–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø –®–ê–ë–õ–û–ù–ê–ú–ò –í–û–ü–†–û–°–û–í
# ==============================================

class TemplateManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞–º–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ò–ò"""
    
    def __init__(self):
        self.templates_path = Path(CONFIG["templates_path"])
        self.templates = self._load_templates()
    
    def _load_templates(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º —à–∞–±–ª–æ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞"""
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—ã—Ç–∞–µ–º—Å—è –µ–≥–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å
        if self.templates_path.exists():
            try:
                with open(self.templates_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    if content:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                        templates = json.loads(content)
                        
                        # ‚≠ê –î–û–ë–ê–í–õ–ï–ù–ê –ü–†–û–í–ï–†–ö–ê –°–¢–†–£–ö–¢–£–†–´ ‚≠ê
                        if not isinstance(templates, dict):
                            print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: templates –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º, –∞ –Ω–µ {type(templates).__name__}")
                            raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö")
                        
                        if "templates" not in templates:
                            print(f"‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'templates'")
                            raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'templates'")
                        
                        if not isinstance(templates["templates"], list):
                            print(f"‚ùå –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: 'templates' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")
                            raise ValueError("'templates' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º")
                        
                        print(f"‚úÖ –®–∞–±–ª–æ–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞: {self.templates_path}")
                        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(templates['templates'])} —à–∞–±–ª–æ–Ω–æ–≤")
                        return templates
                    
            except json.JSONDecodeError as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ JSON –≤ —Ñ–∞–π–ª–µ —à–∞–±–ª–æ–Ω–æ–≤: {e}")
                print(f"‚ùå –°—Ç—Ä–æ–∫–∞ —Å –æ—à–∏–±–∫–æ–π: {e.doc}")
                print(f"‚ùå –ü–æ–∑–∏—Ü–∏—è –æ—à–∏–±–∫–∏: {e.pos}")
                
            except ValueError as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞: {e}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —à–∞–±–ª–æ–Ω–æ–≤: {e}")
                import traceback
                traceback.print_exc()
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç –∏–ª–∏ –æ–Ω –ø—É—Å—Ç–æ–π/–±–∏—Ç—ã–π
        print("üìù –°–æ–∑–¥–∞—é –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã...")
        default_templates = self._get_default_templates()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not self.templates_path.exists():
            self._save_templates(default_templates)
        
        return default_templates
    
    def _get_default_templates(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã"""
        return {
            "templates": [
                {
                    "id": "analytical_report",
                    "name": "üìä –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç",
                    "description": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –±–∞–∑—ã –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏",
                    "prompt": "–¢—ã ‚Äî —Å—Ç–∞—Ä—à–∏–π —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–µ–º–ª–µ–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –∫–∞–¥–∞—Å—Ç—Ä–∞ –∏ –≥—Ä–∞–¥–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è.\n\n–û–°–ù–û–í–ù–û–ï –ü–†–ê–í–ò–õ–û: –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¢–û–õ–¨–ö–û –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.\n\n–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:\n1. –ö–†–ê–¢–ö–ò–ô –û–¢–í–ï–¢: –û—Å–Ω–æ–≤–Ω–æ–π –≤—ã–≤–æ–¥ –≤ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö\n2. –ù–û–†–ú–ê–¢–ò–í–ù–ê–Ø –ë–ê–ó–ê: –ö–ª—é—á–µ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n3. –ê–ù–ê–õ–ò–ó: –°–≤—è–∑—å –Ω–æ—Ä–º —Å –≤–æ–ø—Ä–æ—Å–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n4. –í–´–í–û–î–´: –ü—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏\n\n–í–ê–ñ–ù–û:\n- –ö–∞–∂–¥–æ–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—Ç—å—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏\n- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –ø—Ä—è–º–æ —É–∫–∞–∑—ã–≤–∞–π –Ω–∞ —ç—Ç–æ\n- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –≤–Ω–µ—à–Ω–∏–µ –∑–Ω–∞–Ω–∏—è\n\n–û–¢–í–ï–¢ –≠–ö–°–ü–ï–†–¢–ê-–ê–ù–ê–õ–ò–¢–ò–ö–ê:"
                },
                {
                    "id": "brief_qa",
                    "name": "‚ö° –ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏",
                    "description": "–ö—Ä–∞—Ç–∫–∏–π —Ñ–æ—Ä–º–∞—Ç: –≤–æ–ø—Ä–æ—Å —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—Ä—è–º–æ–π –æ—Ç–≤–µ—Ç –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
                    "prompt": "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–µ–º–ª–µ–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –∫–∞–¥–∞—Å—Ç—Ä–∞.\n\n–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¢–û–õ–¨–ö–û –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.\n\n–ü–æ–¥–≥–æ—Ç–æ–≤—å –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:\n1. –í–û–ü–†–û–° (–°–í–û–ò–ú–ò –°–õ–û–í–ê–ú–ò): –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n2. –ü–†–Ø–ú–û–ô –û–¢–í–ï–¢: –ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n3. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò: –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏\n\n–û–¢–í–ï–¢ –≠–ö–°–ü–ï–†–¢–ê:"
                },
                {
                    "id": "standard",
                    "name": "üìù –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç",
                    "description": "–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º",
                    "prompt": "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–µ–º–ª–µ–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –∫–∞–¥–∞—Å—Ç—Ä–∞.\n\n–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –ø–æ–¥–≥–æ—Ç–æ–≤—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.\n\n–ò–ù–°–¢–†–£–ö–¶–ò–Ø:\n1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—Å–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã\n2. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ø–æ–ª–Ω—ã–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç\n3. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¢–û–õ–¨–ö–û –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤\n4. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —É–∫–∞–∂–∏ —ç—Ç–æ\n\n–°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:\n1. –ü–û–í–¢–û–†–ï–ù–ò–ï –í–û–ü–†–û–°–ê: –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø–æ–∫–∞–∑—ã–≤–∞—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –∑–∞–¥–∞–≤–∞—è —Ä–∞–º–∫–∏ –∞–Ω–∞–ª–∏–∑–∞\n2. –ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –¥–æ—Å–ª–æ–≤–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º\n3. –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º\n4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n5. –í—ã–≤–æ–¥—ã\n\n–û–¢–í–ï–¢ –≠–ö–°–ü–ï–†–¢–ê:"
                }
            ],
            "default_template": "brief_qa",
            "last_updated": datetime.now().isoformat()
        }
    
    def _save_templates(self, templates: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º —à–∞–±–ª–æ–Ω—ã –≤ —Ñ–∞–π–ª"""
        try:
            self.templates_path.parent.mkdir(exist_ok=True, parents=True)
            with open(self.templates_path, 'w', encoding='utf-8') as f:
                json.dump(templates, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —à–∞–±–ª–æ–Ω–æ–≤: {e}")
    
    def get_templates_list(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤"""
        return self.templates.get("templates", [])
    
    def get_template_by_id(self, template_id: str) -> Optional[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —à–∞–±–ª–æ–Ω –ø–æ ID"""
        for template in self.templates.get("templates", []):
            if template.get("id") == template_id:
                return template
        return None
    
    def get_default_template(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —à–∞–±–ª–æ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        default_id = self.templates.get("default_template", "standard")
        template = self.get_template_by_id(default_id)
        if template:
            return template
        else:
            # –ï—Å–ª–∏ —à–∞–±–ª–æ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –Ω–∞–π–¥–µ–Ω, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∏–∑ —Å–ø–∏—Å–∫–∞
            templates_list = self.get_templates_list()
            if templates_list:
                return templates_list[0]
            # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç —à–∞–±–ª–æ–Ω–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π
            return {"id": "empty", "name": "–ü—É—Å—Ç–æ–π", "description": "", "prompt": ""}
    
    def update_templates(self, new_templates: Dict):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —à–∞–±–ª–æ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ñ–∞–π–ª"""
        self.templates = new_templates
        self._save_templates(new_templates)
    
    def reload_templates(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞"""
        self.templates = self._load_templates()

# ==============================================
# –°–ò–°–¢–ï–ú–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø –ë–ê–ó–û–ô –†–ê–ó–î–ï–õ–û–í
# ==============================================

class SimpleSectionDatabase:
    """–ü—Ä–æ—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π —Ä–∞–∑–¥–µ–ª–æ–≤"""
    
    def __init__(self):
        self.db_path = Path(CONFIG["database_path"])
        self.sections_db = self.db_path / "sections.json"
        self.metadata_db = self.db_path / "metadata.json"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
        self.sections = self._load_sections()
        self.metadata = self._load_metadata()
    
    def _clean_text_from_comments(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        if not text:
            return text
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è - –¢–û–õ–¨–ö–û –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        patterns_to_remove = [
            r'\(–≤ —Ä–µ–¥\. [^)]*\)',
            r'\(–≤–≤–µ–¥–µ–Ω–∞ [^)]*\)',
            r'\(–ø\. \d+ –≤ —Ä–µ–¥\. [^)]*\)',
            r'\[[^\]]*–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç[^\]]*\]',
            r'–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–ü–ª—é—Å: –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ\..*?(?=\n\n|\Z)',
            r'–§–µ–¥–µ—Ä–∞–ª—å–Ω(?:–æ–≥–æ|—ã–º) –∑–∞–∫–æ–Ω–æ–º –æ—Ç \d{2}\.\d{2}\.\d{4} [‚ÑñN]\d+-\S+',
            r'—Å–º\. [^.]*\.',
            r'—Ä–µ–¥\. \d{2}\.\d{2}\.\d{4}',
            r'¬©.*',
            r'\(–ø\. \d+\.\d –≤–≤–µ–¥–µ–Ω –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–º –∑–∞–∫–æ–Ω–æ–º –æ—Ç \d{2}\.\d{2}\.\d{4} N \d+-\S+\)',
            r'\(–≤ —Ä–µ–¥\. –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–∞ –æ—Ç \d{2}\.\d{2}\.\d{4} N \d+-\S+\)'
        ]
        
        cleaned_text = text
        
        # –û—á–∏—â–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –æ—Ç–¥–µ–ª—å–Ω–æ
        for pattern in patterns_to_remove:
            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE|re.DOTALL)
        
        return cleaned_text
    
    def _clean_special_characters(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏"""
        if not text:
            return text
        
        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–∞–±—É–ª—è—Ü–∏–∏
        cleaned = re.sub(r'[ \t]+', ' ', text)
        
        # –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –º—è–≥–∫–∏—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ –∏ –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        cleaned = cleaned.replace('\xad', '')  # –º—è–≥–∫–∏–π –ø–µ—Ä–µ–Ω–æ—Å
        cleaned = cleaned.replace('\xa0', ' ')  # –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–π –ø—Ä–æ–±–µ–ª
        
        # –£–¥–∞–ª—è–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Å–∏–º–≤–æ–ª—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        cleaned = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', cleaned)
        
        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º 2 –ø–æ–¥—Ä—è–¥)
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        cleaned = cleaned.strip()
        
        # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω
        cleaned = re.sub(r' +', ' ', cleaned)
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        lines = cleaned.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if line:  # –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                cleaned_lines.append(line)
        
        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫
        cleaned = '\n'.join(cleaned_lines)
        
        return cleaned
    
    def _load_sections(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É —Ä–∞–∑–¥–µ–ª–æ–≤"""
        if self.sections_db.exists():
            try:
                with open(self.sections_db, 'r', encoding='utf-8') as f:
                    sections = json.load(f)
                    return sections
            except:
                return []
        return []
    
    def _load_metadata(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–∞–∑—ã"""
        if self.metadata_db.exists():
            try:
                with open(self.metadata_db, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {
            "created_at": "",
            "last_updated": "",
            "total_sections": 0,
            "total_documents": 0,
            "by_folder": {}
        }
    
    def save_database(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑—É –Ω–∞ –¥–∏—Å–∫"""
        self.db_path.mkdir(exist_ok=True)
        
        with open(self.sections_db, 'w', encoding='utf-8') as f:
            json.dump(self.sections, f, ensure_ascii=False, indent=2)
        
        with open(self.metadata_db, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)
    
    def scan_and_build_database(self):
        """–°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫–∏ –∏ —Å—Ç—Ä–æ–∏–º –±–∞–∑—É —Ä–∞–∑–¥–µ–ª–æ–≤"""
        print("üîç –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫...")
        
        all_sections = []
        folder_stats = {}
        
        for folder_name, folder_path in CONFIG["folders"].items():
            if not folder_path or not Path(folder_path).exists():
                print(f"‚ö† –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
                continue
            
            folder = Path(folder_path)
            print(f"\nüìÅ –°–∫–∞–Ω–∏—Ä—É–µ–º: {folder} ({folder_name})")
            
            # –ò—â–µ–º —Ñ–∞–π–ª—ã
            files = list(folder.rglob("*.md")) + list(folder.rglob("*.txt"))
            
            folder_sections = 0
            folder_documents = len(files)
            
            for file_path in files:
                print(f"  üìÑ {file_path.name}...", end="")
                
                try:
                    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                    content = self._read_file_with_encoding(file_path)
                    
                    if content is None:
                        print(f" ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª")
                        continue
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ YAML –∑–∞–≥–æ–ª–æ–≤–∫–∞
                    metadata = self._extract_yaml_metadata(content)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    document_title = metadata.get('title', file_path.stem)
                    
                    # –û–ß–ò–©–ê–ï–ú –¢–ï–ö–°–¢ –û–¢ –°–õ–£–ñ–ï–ë–ù–´–• –°–ò–ú–í–û–õ–û–í
                    cleaned_content = self._clean_special_characters(content)
                    
                    # –†–ê–ó–ë–ò–í–ê–ï–ú –î–û–ö–£–ú–ï–ù–¢ –ù–ê –†–ê–ó–î–ï–õ–´ –í –ó–ê–í–ò–°–ò–ú–û–°–¢–ò –û–¢ –¢–ò–ü–ê –ü–ê–ü–ö–ò
                    sections = self._split_document_by_type(
                        cleaned_content,
                        file_path, 
                        folder_name, 
                        document_title
                    )
                    
                    print(f" ‚Üí {len(sections)} —Ä–∞–∑–¥–µ–ª–æ–≤")
                    folder_sections += len(sections)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª—ã –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                    for i, section in enumerate(sections):
                        # –û–ß–ò–©–ê–ï–ú –ö–û–ù–¢–ï–ù–¢ –ö–ê–ñ–î–û–ì–û –†–ê–ó–î–ï–õ–ê –û–¢ –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í
                        section_content = section.get("content", "")
                        final_content = self._clean_text_from_comments(section_content)
                        
                        all_sections.append({
                            "id": f"{file_path.stem}_{i}_{uuid.uuid4().hex[:8]}",
                            "folder": folder_name,
                            "document": file_path.name,
                            "document_title": document_title,
                            "document_path": str(file_path),
                            "title": section.get("title", document_title),
                            "content": final_content,
                            "section_type": section.get("type", "text"),
                            "word_count": len(final_content.split()),
                            "metadata": metadata,
                            "selected": False
                        })
                        
                except Exception as e:
                    print(f" ‚ùå –û—à–∏–±–∫–∞: {e}")
                    import traceback
                    traceback.print_exc()
            
            folder_stats[folder_name] = {
                "documents": folder_documents,
                "sections": folder_sections
            }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É
        self.sections = all_sections
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.metadata = {
            "created_at": self.metadata.get("created_at", datetime.now().isoformat()),
            "last_updated": datetime.now().isoformat(),
            "total_sections": len(all_sections),
            "total_documents": sum(stats["documents"] for stats in folder_stats.values()),
            "by_folder": folder_stats
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        self.save_database()
        
        print(f"\n‚úÖ –ë–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞!")
        print(f"   –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {self.metadata['total_documents']}")
        print(f"   –í—Å–µ–≥–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {self.metadata['total_sections']}")
        
        for folder_name, stats in folder_stats.items():
            print(f"   üìÅ {folder_name}: {stats['documents']} –¥–æ–∫. ‚Üí {stats['sections']} —Ä–∞–∑–¥.")
        
        return all_sections
    
    def _read_file_with_encoding(self, file_path: Path) -> Optional[str]:
        """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
        try:
            with open(file_path, 'rb') as f:
                raw_data = f.read()
            
            if not raw_data:
                return ""
            
            encoding_result = chardet.detect(raw_data)
            encoding = encoding_result['encoding']
            confidence = encoding_result['confidence']
            
            if not encoding or confidence < 0.7:
                encodings_to_try = ['utf-8', 'utf-16-le', 'utf-16-be', 'cp1251', 'iso-8859-1']
            else:
                encodings_to_try = [encoding, 'utf-8', 'utf-16-le', 'utf-16-be']
            
            for enc in encodings_to_try:
                try:
                    if enc.startswith('utf-16'):
                        if len(raw_data) >= 2:
                            bom = raw_data[:2]
                            if bom == b'\xff\xfe':
                                content = raw_data[2:].decode('utf-16-le')
                                return content
                            elif bom == b'\xfe\xff':
                                content = raw_data[2:].decode('utf-16-be')
                                return content
                            else:
                                try:
                                    content = raw_data.decode('utf-16-le')
                                    return content
                                except:
                                    content = raw_data.decode('utf-16-be')
                                    return content
                    
                    content = raw_data.decode(enc, errors='strict')
                    return content
                except (UnicodeDecodeError, LookupError):
                    continue
            
            try:
                return raw_data.decode('utf-8', errors='ignore')
            except:
                return raw_data.decode('latin-1', errors='ignore')
                
        except Exception as e:
            print(f"  ‚ö† –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path.name}: {e}")
            return None
    
    def _extract_yaml_metadata(self, content: str) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ YAML –∑–∞–≥–æ–ª–æ–≤–∫–∞ –≤ –Ω–∞—á–∞–ª–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        metadata = {}
        
        try:
            content_stripped = content.strip()
            if content_stripped.startswith('---'):
                parts = content_stripped.split('---', 2)
                if len(parts) >= 3:
                    yaml_content = parts[1].strip()
                    if yaml_content:
                        metadata = yaml.safe_load(yaml_content) or {}
        except (yaml.YAMLError, AttributeError) as e:
            print(f"  ‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å YAML: {e}")
        
        if not isinstance(metadata, dict):
            metadata = {}
        
        return metadata
    
    def _split_document_by_type(self, content: str, file_path: Path, folder_type: str, doc_title: str) -> List[Dict]:
        """–†–∞–∑–±–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø–∞–ø–∫–∏"""
        
        if folder_type == "normative":
            return self._split_normative_document(content, file_path, doc_title)
        elif folder_type == "methodology":
            return self._split_methodology_document(content, file_path, doc_title)
        elif folder_type == "structured":
            return self._split_structured_document(content, file_path, doc_title)
        elif folder_type == "expertise":
            return self._split_expertise_document(content, file_path, doc_title)
        else:
            return [{
                "title": doc_title,
                "content": content.strip() if content else "",
                "type": "full_document"
            }]
    
    def _split_normative_document(self, content: str, file_path: Path, doc_title: str) -> List[Dict]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ '–ì–õ–ê–í–ê' –∏–ª–∏ '–ì–ª–∞–≤–∞' —Å –Ω–æ–º–µ—Ä–æ–º"""
        sections = []
        
        if not content:
            return [{
                "title": doc_title,
                "content": "",
                "type": "empty_document"
            }]
        
        content_to_process = content
        if content.strip().startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                content_to_process = parts[2].strip()
        
        lines = content_to_process.split('\n')
        current_section = []
        current_title = doc_title
        current_type = "document"
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–ª–∞–≤ (–¢–û–õ–¨–ö–û –ì–õ–ê–í–ê, –±–µ–∑ –°—Ç–∞—Ç–µ–π)
        patterns = [
            (r'^–ì–õ–ê–í–ê\s+[IVXLCDM\d]+[\s\.\-:].*$', "chapter"),
            (r'^–ì–ª–∞–≤–∞\s+[IVXLCDM\d]+[\s\.\-:].*$', "chapter"),
            (r'^–ì–õ–ê–í–ê\s+[0-9]+[\s\.\-:].*$', "chapter"),
            (r'^–ì–ª–∞–≤–∞\s+[0-9]+[\s\.\-:].*$', "chapter"),
        ]
        
        for line in lines:
            is_header = False
            for pattern, section_type in patterns:
                match = re.match(pattern, line.strip())
                if match:
                    if current_section:
                        sections.append({
                            "title": current_title,
                            "content": "\n".join(current_section).strip(),
                            "type": current_type
                        })
                    
                    current_title = line.strip()
                    current_type = section_type
                    current_section = []
                    is_header = True
                    break
            
            if not is_header:
                current_section.append(line)
        
        if current_section:
            sections.append({
                "title": current_title,
                "content": "\n".join(current_section).strip(),
                "type": current_type
            })
        
        if not sections:
            sections.append({
                "title": doc_title,
                "content": content_to_process.strip(),
                "type": "full_document"
            })
        
        return sections
    
    def _split_methodology_document(self, content: str, file_path: Path, doc_title: str) -> List[Dict]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏ 1 –∏ 2 —É—Ä–æ–≤–Ω—è markdown"""
        sections = []
        
        if not content:
            return [{
                "title": doc_title,
                "content": "",
                "type": "empty_document"
            }]
        
        content_to_process = content
        if content.strip().startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                content_to_process = parts[2].strip()
        
        lines = content_to_process.split('\n')
        current_section = []
        current_title = doc_title
        current_type = "document"
        
        patterns = [
            (r'^#\s+(.+)$', "h1"),
            (r'^##\s+(.+)$', "h2"),
        ]
        
        for line in lines:
            is_header = False
            for pattern, section_type in patterns:
                match = re.match(pattern, line.strip())
                if match:
                    if current_section:
                        sections.append({
                            "title": current_title,
                            "content": "\n".join(current_section).strip(),
                            "type": current_type
                        })
                    
                    current_title = match.group(1)
                    current_type = section_type
                    current_section = []
                    is_header = True
                    break
            
            if not is_header:
                current_section.append(line)
        
        if current_section:
            sections.append({
                "title": current_title,
                "content": "\n".join(current_section).strip(),
                "type": current_type
            })
        
        if not sections:
            sections.append({
                "title": doc_title,
                "content": content_to_process.strip(),
                "type": "full_document"
            })
        
        return sections
    
    def _split_structured_document(self, content: str, file_path: Path, doc_title: str) -> List[Dict]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–º —Å–∫–æ–±–∫–∞–º"""
        sections = []
        
        if not content:
            return [{
                "title": doc_title,
                "content": "",
                "type": "empty_document"
            }]
        
        content_to_process = content
        if content.strip().startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                content_to_process = parts[2].strip()
        
        lines = content_to_process.split('\n')
        current_section = []
        current_title = doc_title
        current_type = "document"
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        bracket_pattern = r'^\[([^\[\]]+)\]$'
        
        for line in lines:
            line_stripped = line.strip()
            is_header = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
            match = re.match(bracket_pattern, line_stripped)
            if match:
                header_content = match.group(1).strip()
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º
                # –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–µ —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã –∏–ª–∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã)
                if (len(header_content) > 3 and 
                    len(header_content) <= 200 and
                    re.search(r'[–ê-–Ø–∞-—è–Å—ëA-Za-z]', header_content)):
                    
                    if current_section:
                        sections.append({
                            "title": current_title,
                            "content": "\n".join(current_section).strip(),
                            "type": current_type
                        })
                    
                    current_title = header_content
                    current_type = "bracketed_section"
                    current_section = []
                    is_header = True
            
            if not is_header:
                current_section.append(line)
        
        if current_section:
            sections.append({
                "title": current_title,
                "content": "\n".join(current_section).strip(),
                "type": current_type
            })
        
        if not sections:
            sections.append({
                "title": doc_title,
                "content": content_to_process.strip(),
                "type": "full_document"
            })
        
        return sections
    
    def _split_expertise_document(self, content: str, file_path: Path, doc_title: str) -> List[Dict]:
        """–≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–µ–∑ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"""
        
        if not content:
            return [{
                "title": doc_title,
                "content": "",
                "type": "empty_document"
            }]
        
        content_to_process = content
        if content.strip().startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                content_to_process = parts[2].strip()
        
        return [{
            "title": doc_title,
            "content": content_to_process.strip(),
            "type": "expertise_document"
        }]
    
    def get_sections_for_display(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —É–¥–æ–±–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π"""
        display_data = []
        
        for section in self.sections:
            section_id = section.get("id", str(uuid.uuid4()))
            folder = section.get("folder", "unknown")
            doc_file = section.get("document", "")
            doc_title = section.get("document_title", doc_file)
            section_title = section.get("title", doc_title)
            section_type = section.get("section_type", "text")
            content = section.get("content", "")
            word_count = section.get("word_count", 0)
            selected = section.get("selected", False)
            
            # –°–æ–∫—Ä–∞—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            short_doc_title = doc_title[:40] + "..." if len(doc_title) > 40 else doc_title
            short_section_title = section_title[:60] + "..." if len(section_title) > 60 else section_title
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            if folder == "structured" and not section_title.startswith("["):
                short_section_title = f"[{short_section_title}]"
                section_title = f"[{section_title}]"
            
            display_data.append({
                "id": section_id,
                "folder": folder,
                "document": short_doc_title,
                "document_full": doc_title,
                "file": doc_file,
                "section": short_section_title,
                "section_full": section_title,
                "type": section_type,
                "words": word_count,
                "selected": selected,
                "content_full": content
            })
        
        return display_data
    
    def update_selections(self, selected_ids: List[str]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤—ã–±–æ—Ä —ç–∫—Å–ø–µ—Ä—Ç–∞"""
        for section in self.sections:
            section_id = section.get("id", "")
            section["selected"] = section_id in selected_ids
        
        self.save_database()
    
    def get_selected_sections(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–º —Ä–∞–∑–¥–µ–ª—ã"""
        return [s for s in self.sections if s.get("selected", False)]
    
    def clear_selections(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ –≤—ã–±–æ—Ä—ã"""
        for section in self.sections:
            section["selected"] = False
        
        self.save_database()

# ==============================================
# –ì–ï–ù–ï–†–ê–¢–û–† –§–ê–ô–õ–û–í –î–õ–Ø –≠–ö–°–ü–ï–†–¢–ê
# ==============================================

class ExpertFileGenerator:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–∞ —Å DeepSeek"""
    
    @staticmethod
    def _clean_content_for_output(content: str) -> str:
        """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ —Ñ–∞–π–ª—ã - —É–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏"""
        if not content:
            return content
        
        # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º 2 –ø–æ–¥—Ä—è–¥)
        cleaned = re.sub(r'\n{3,}', '\n\n', content)
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        cleaned = cleaned.strip()
        
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        lines = cleaned.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if line:  # –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                # –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏
                line = re.sub(r' +', ' ', line)
                cleaned_lines.append(line)
        
        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ, –æ—Å—Ç–∞–≤–ª—è—è –ø–æ –æ–¥–Ω–æ–π –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏
        if not cleaned_lines:
            return ""
        
        result = []
        for i, line in enumerate(cleaned_lines):
            result.append(line)
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è
            # –∏ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞
            if i < len(cleaned_lines) - 1 and cleaned_lines[i+1]:
                result.append('')
        
        return '\n'.join(result)
    
    @staticmethod
    def create_prompt_file(selected_sections: List[Dict], output_dir: Path, 
                         template_manager: TemplateManager, selected_template_id: str) -> Optional[Path]:
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª —Å –ø—Ä–æ–º—Ç–æ–º –¥–ª—è DeepSeek –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å–µ—Å—Å–∏–∏"""
        if not selected_sections:
            return None
        
        session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_dir = output_dir / session_id
        session_dir.mkdir(exist_ok=True, parents=True)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω
        selected_template = template_manager.get_template_by_id(selected_template_id)
        if not selected_template:
            selected_template = template_manager.get_default_template()
        
        # 1. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª all_sections.md
        all_sections_file = session_dir / "all_sections.md"
        try:
            with open(all_sections_file, 'w', encoding='utf-8') as f:
                f.write("# –í–´–ë–†–ê–ù–ù–´–ï –†–ê–ó–î–ï–õ–´ –î–õ–Ø –û–¢–í–ï–¢–ê\n\n")
                f.write(f"**–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–π —à–∞–±–ª–æ–Ω:** {selected_template.get('name', '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π')}\n\n")
                
                by_folder = {}
                for section in selected_sections:
                    folder = section.get("folder", "unknown")
                    if folder not in by_folder:
                        by_folder[folder] = []
                    by_folder[folder].append(section)
                
                folder_names = {
                    "normative": "üìñ –ù–û–†–ú–ê–¢–ò–í–ù–´–ï –ê–ö–¢–´",
                    "methodology": "üìö –ú–ï–¢–û–î–ò–ß–ï–°–ö–ò–ï –ú–ê–¢–ï–†–ò–ê–õ–´",
                    "structured": "üóÇÔ∏è –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´",
                    "expertise": "üë®‚Äç‚öñÔ∏è –≠–ö–°–ü–ï–†–¢–ù–´–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–Ø"
                }
                
                for folder, sections in by_folder.items():
                    folder_name = folder_names.get(folder, folder)
                    
                    f.write(f"\n## {folder_name}\n\n")
                    
                    for section in sections:
                        # –î–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∫–æ–±–∫–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        section_title = section.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                        if folder == "structured" and not section_title.startswith("["):
                            section_title = f"[{section_title}]"
                        
                        f.write(f"### {section_title}\n")
                        f.write(f"*–ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:* {section.get('document_title', section.get('document', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'))}\n")
                        f.write(f"*–§–∞–π–ª:* {section.get('document', '')}\n")
                        f.write(f"*–¢–∏–ø —Ä–∞–∑–¥–µ–ª–∞:* {section.get('section_type', 'text')}\n")
                        f.write(f"*–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤:* {section.get('word_count', 0)}\n")
                        
                        metadata = section.get('metadata', {})
                        if metadata and isinstance(metadata, dict):
                            if metadata.get('title'):
                                f.write(f"*–ù–∞–∑–≤–∞–Ω–∏–µ:* {metadata['title']}\n")
                            if metadata.get('author'):
                                f.write(f"*–ê–≤—Ç–æ—Ä:* {metadata['author']}\n")
                            if metadata.get('date'):
                                f.write(f"*–î–∞—Ç–∞:* {metadata['date']}\n")
                        
                        # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
                        cleaned_content = ExpertFileGenerator._clean_content_for_output(section.get('content', ''))
                        f.write(f"\n{cleaned_content}\n\n")
                        f.write("---\n\n")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ all_sections.md: {e}")
            return None
        
        # 2. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª deepseek_prompt.txt
        prompt_file = session_dir / "deepseek_prompt.txt"
        try:
            with open(prompt_file, 'w', encoding='utf-8') as f:
                prompt_content = ExpertFileGenerator._generate_prompt(
                    selected_sections, 
                    selected_template.get('prompt', '')
                )
                f.write(prompt_content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ deepseek_prompt.txt: {e}")
            return None
        
        # 3. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª report.txt
        report_file = session_dir / "report.txt"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                report_content = ExpertFileGenerator._generate_report(
                    selected_sections, 
                    session_id, 
                    selected_template
                )
                f.write(report_content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ report.txt: {e}")
            return None
        
        # 4. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª sections_data.json
        json_file = session_dir / "sections_data.json"
        try:
            with open(json_file, 'w', encoding='utf-8') as f:
                # –£–ø—Ä–æ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è JSON
                simplified_sections = []
                for section in selected_sections:
                    # –î–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∫–æ–±–∫–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title = section.get("title", "")
                    if section.get("folder") == "structured" and not title.startswith("["):
                        title = f"[{title}]"
                    
                    simplified = {
                        "id": section.get("id"),
                        "folder": section.get("folder"),
                        "document": section.get("document"),
                        "document_title": section.get("document_title"),
                        "title": title,
                        "content": section.get("content"),
                        "section_type": section.get("section_type"),
                        "word_count": section.get("word_count"),
                        "metadata": section.get("metadata", {})
                    }
                    simplified_sections.append(simplified)
                
                json.dump(simplified_sections, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ sections_data.json: {e}")
            return None
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à–∞–±–ª–æ–Ω–µ
        template_file = session_dir / "template_info.json"
        try:
            with open(template_file, 'w', encoding='utf-8') as f:
                template_info = {
                    "template_id": selected_template.get("id"),
                    "template_name": selected_template.get("name"),
                    "template_description": selected_template.get("description"),
                    "created_at": datetime.now().isoformat()
                }
                json.dump(template_info, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ template_info.json: {e}")
            return None
        
        print(f"\n‚úÖ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã –≤ –ø–∞–ø–∫–µ: {session_dir}")
        print(f"üìÑ 1. all_sections.md - –≤—Å–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã")
        print(f"ü§ñ 2. deepseek_prompt.txt - –≥–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º—Ç –¥–ª—è DeepSeek")
        print(f"üìä 3. report.txt - –æ—Ç—á–µ—Ç –ø–æ —Å–µ—Å—Å–∏–∏")
        print(f"üìÅ 4. sections_data.json - –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON")
        print(f"üéØ 5. template_info.json - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —à–∞–±–ª–æ–Ω–µ")
        
        return session_dir
    
    @staticmethod
    def _generate_prompt(sections: List[Dict], template_prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º—Ç –¥–ª—è DeepSeek (–≤–æ–ø—Ä–æ—Å –ü–ï–†–ï–î –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏)"""
        prompt = ""
        
        # 1. –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å (—à–∞–±–ª–æ–Ω)
        prompt += template_prompt
        prompt += "\n\n"
        
        # 2. –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª—ã
        prompt += "–ú–ê–¢–ï–†–ò–ê–õ–´ –î–õ–Ø –û–¢–í–ï–¢–ê:\n"
        prompt += "=" * 60 + "\n\n"
        
        for i, section in enumerate(sections, 1):
            folder = section.get("folder", "unknown")
            folder_name = {
                "normative": "–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∞–∫—Ç",
                "methodology": "–ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª",
                "structured": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç",
                "expertise": "–≠–∫—Å–ø–µ—Ä—Ç–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ"
            }.get(folder, "–ú–∞—Ç–µ—Ä–∏–∞–ª")
            
            section_title = section.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
            # –î–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∫–æ–±–∫–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if folder == "structured" and not section_title.startswith("["):
                section_title = f"[{section_title}]"
                
            doc_title = section.get("document_title", section.get("document", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"))
            doc_file = section.get("document", "")
            section_type = section.get("section_type", "text")
            
            prompt += f"\n{'='*60}\n"
            prompt += f"–ú–ê–¢–ï–†–ò–ê–õ {i}: {section_title}\n"
            prompt += f"–¢–∏–ø: {folder_name} | –î–æ–∫—É–º–µ–Ω—Ç: {doc_title}\n"
            prompt += f"–§–∞–π–ª: {doc_file} | –¢–∏–ø —Ä–∞–∑–¥–µ–ª–∞: {section_type}\n"
            
            metadata = section.get('metadata', {})
            if metadata and isinstance(metadata, dict):
                if metadata.get('author'):
                    prompt += f"–ê–≤—Ç–æ—Ä: {metadata['author']} | "
                if metadata.get('date'):
                    prompt += f"–î–∞—Ç–∞: {metadata['date']}"
                prompt += f"\n"
            
            prompt += f"{'-'*40}\n\n"
            
            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
            cleaned_content = ExpertFileGenerator._clean_content_for_output(section.get('content', ''))
            prompt += f"{cleaned_content}\n"
        
        prompt += f"\n{'='*60}\n\n"
        
        return prompt
    
    @staticmethod
    def _generate_report(sections: List[Dict], session_id: str, template: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ —Å–µ—Å—Å–∏–∏"""
        by_folder = {}
        total_words = 0
        
        for section in sections:
            folder = section.get("folder", "unknown")
            if folder not in by_folder:
                by_folder[folder] = []
            by_folder[folder].append(section)
            total_words += section.get("word_count", 0)
        
        folder_names = {
            "normative": "–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã",
            "methodology": "–ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã",
            "structured": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã",
            "expertise": "–≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è"
        }
        
        report = f"–û–¢–ß–ï–¢ –ü–û –°–ï–°–°–ò–ò –≠–ö–°–ü–ï–†–¢–ê\n"
        report += f"========================\n\n"
        report += f"ID —Å–µ—Å—Å–∏–∏: {session_id}\n"
        report += f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        report += f"–í–´–ë–†–ê–ù–ù–´–ô –®–ê–ë–õ–û–ù:\n"
        report += f"‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ: {template.get('name', '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π')}\n"
        report += f"‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {template.get('description', '')}\n"
        report += f"‚Ä¢ ID: {template.get('id', 'standard')}\n\n"
        
        report += f"–°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n"
        report += f"‚Ä¢ –í—Å–µ–≥–æ –≤—ã–±—Ä–∞–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(sections)}\n"
        report += f"‚Ä¢ –û–±—â–∏–π –æ–±—ä–µ–º: {total_words} —Å–ª–æ–≤\n\n"
        
        if by_folder:
            report += f"–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –¢–ò–ü–ê–ú –ú–ê–¢–ï–†–ò–ê–õ–û–í:\n"
            for folder, folder_sections in by_folder.items():
                name = folder_names.get(folder, folder)
                words = sum(s.get("word_count", 0) for s in folder_sections)
                report += f"‚Ä¢ {name}: {len(folder_sections)} —Ä–∞–∑–¥–µ–ª–æ–≤ ({words} —Å–ª–æ–≤)\n"
        
        report += f"\n–°–ü–ò–°–û–ö –í–´–ë–†–ê–ù–ù–´–• –†–ê–ó–î–ï–õ–û–í:\n"
        for i, section in enumerate(sections, 1):
            folder = section.get("folder", "unknown")
            folder_icon = {
                "normative": "üìñ",
                "methodology": "üìö",
                "structured": "üóÇÔ∏è",
                "expertise": "üë®‚Äç‚öñÔ∏è"
            }.get(folder, "üìÑ")
            
            section_title = section.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
            # –î–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∫–æ–±–∫–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if folder == "structured" and not section_title.startswith("["):
                section_title = f"[{section_title}]"
                
            doc_title = section.get("document_title", section.get("document", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"))
            word_count = section.get("word_count", 0)
            
            report += f"{i}. {folder_icon} {section_title} ({word_count} —Å–ª–æ–≤)\n"
            report += f"   –î–æ–∫—É–º–µ–Ω—Ç: {doc_title}\n"
        
        report += f"\n–§–ê–ô–õ–´ –°–ï–°–°–ò–ò:\n"
        report += f"1. all_sections.md - –≤—Å–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã\n"
        report += f"2. deepseek_prompt.txt - –ø—Ä–æ–º—Ç –¥–ª—è DeepSeek\n"
        report += f"3. report.txt - —ç—Ç–æ—Ç –æ—Ç—á–µ—Ç\n"
        report += f"4. sections_data.json - –¥–∞–Ω–Ω—ã–µ –≤ JSON\n"
        report += f"5. template_info.json - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —à–∞–±–ª–æ–Ω–µ\n"
        
        return report

# ==============================================
# –í–ï–ë-–ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø –≠–ö–°–ü–ï–†–¢–ê (Streamlit)
# ==============================================

# –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –¥–∏–∑–∞–π–Ω –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
hide_streamlit_style = """
<style>
/* –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã */
.section-item {
    border: 1px solid #e0e0e0;
    border-radius: 4px;
    margin-bottom: 4px;
    background-color: white;
    transition: all 0.2s;
}
.section-item:hover {
    border-color: #4CAF50;
    box-shadow: 0 1px 2px rgba(0,0,0,0.05);
}
.section-header {
    font-weight: 600;
    font-size: 0.9rem;
    margin-bottom: 2px;
}
.section-meta {
    font-size: 0.75rem;
    margin-bottom: 2px;
}
.section-title {
    font-weight: 500;
    font-size: 0.85rem;
    margin-top: 2px;
    margin-bottom: 0;
}
.selected-section {
    border-color: #4CAF50;
    background-color: #f8fff8;
}

/* –°—Ç–∏–ª–∏ –¥–ª—è —Ç–µ–º–Ω–æ–π —Ç–µ–º—ã */
[data-theme="dark"] .section-item {
    background-color: #2d2d2d;
    border-color: #555;
}
[data-theme="dark"] .section-header {
    color: #ffffff !important;
}
[data-theme="dark"] .section-meta {
    color: #cccccc !important;
}
[data-theme="dark"] .section-title {
    color: #f0f0f0 !important;
}
[data-theme="dark"] .selected-section {
    background-color: #1e3a1e;
    border-color: #4CAF50;
}

/* –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ª–∏—à–Ω–∏–µ –æ—Ç—Å—Ç—É–ø—ã –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ */
div.stCheckbox > div > div {
    margin: 0 !important;
    padding: 0 !important;
}
div[data-testid="stVerticalBlock"] > div {
    margin-bottom: 0 !important;
}
/* –£–º–µ–Ω—å—à–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ */
div.stContainer {
    padding-top: 1px !important;
    padding-bottom: 1px !important;
}
/* –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ —á–µ–∫–±–æ–∫—Å—ã */
.stCheckbox label {
    padding: 1px 0 !important;
    min-height: auto !important;
}

/* –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—Å—Ç—ã–µ –ª–∏–Ω–∏–∏ –≤ —Ç–µ–º–Ω–æ–π —Ç–µ–º–µ */
[data-theme="dark"] hr {
    border-color: #444 !important;
    margin: 2px 0 !important;
}

/* –°—Ç–∏–ª–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ —à–∞–±–ª–æ–Ω–∞ */
.template-card {
    border: 1px solid #e0e0e0;
    border-radius: 8px;
    padding: 12px;
    margin-bottom: 8px;
    cursor: pointer;
    transition: all 0.2s;
}
.template-card:hover {
    border-color: #4CAF50;
    background-color: #f8fff8;
}
.template-card.selected {
    border-color: #4CAF50;
    background-color: #e8f5e8;
    border-width: 2px;
}
.template-name {
    font-weight: 600;
    font-size: 1rem;
    margin-bottom: 4px;
}
.template-description {
    font-size: 0.85rem;
    color: #666;
    margin-bottom: 0;
}
[data-theme="dark"] .template-card {
    border-color: #555;
    background-color: #2d2d2d;
}
[data-theme="dark"] .template-card:hover {
    border-color: #4CAF50;
    background-color: #1e3a1e;
}
[data-theme="dark"] .template-card.selected {
    border-color: #4CAF50;
    background-color: #1e3a1e;
}
[data-theme="dark"] .template-description {
    color: #aaa;
}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —à–∞–±–ª–æ–Ω–æ–≤
@st.cache_resource
def init_database():
    return SimpleSectionDatabase()

@st.cache_resource
def init_template_manager():
    return TemplateManager()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏
if 'db' not in st.session_state:
    st.session_state.db = init_database()
    st.session_state.template_manager = init_template_manager()
    st.session_state.notifications = []
    st.session_state.last_update_time = datetime.now()
    st.session_state.current_filter_hash = ""
    st.session_state.has_unsaved_changes = False
    st.session_state.session_dir = None
    st.session_state.files_created = False
    st.session_state.selected_template = st.session_state.template_manager.get_default_template()["id"]

db = st.session_state.db
template_manager = st.session_state.template_manager

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
def add_notification(message, type="info"):
    if 'notifications' not in st.session_state:
        st.session_state.notifications = []
    
    st.session_state.notifications.append({
        "message": message,
        "type": type,
        "time": datetime.now().strftime("%H:%M:%S")
    })
    
    if len(st.session_state.notifications) > 10:
        st.session_state.notifications.pop(0)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ë–∞–∑–∞ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ì–ª–∞–≤–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
st.title("üìö –ë–ê–ó–ê –†–ê–ó–î–ï–õ–û–í –î–û–ö–£–ú–ï–ù–¢–û–í")
st.markdown("---")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∫–ª–∞–¥–∫–∏
tab1, tab2, tab3, tab4 = st.tabs([
    "üìã –í—ã–±–æ—Ä —Ä–∞–∑–¥–µ–ª–æ–≤",
    "üéØ –í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞", 
    "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏",
    "üõ†Ô∏è –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ"
])

# ==============================================
# –í–ö–õ–ê–î–ö–ê 1: –í–´–ë–û–† –†–ê–ó–î–ï–õ–û–í (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)
# ==============================================

with tab1:
    st.subheader("üìã –í–´–ë–û–† –†–ê–ó–î–ï–õ–û–í –î–õ–Ø –≠–ö–°–ü–ï–†–¢–ù–û–ì–û –û–¢–í–ï–¢–ê")
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    display_data = db.get_sections_for_display()
    
    if not display_data:
        st.info("–ë–∞–∑–∞ –ø—É—Å—Ç–∞. –ù–∞–∂–º–∏—Ç–µ '–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–∞–ø–∫–∏' –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
    else:
        # –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –ø–∞–Ω–µ–ª—å —Ñ–∏–ª—å—Ç—Ä–æ–≤
        with st.container():
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # –§–∏–ª—å—Ç—Ä –ø–æ –ø–∞–ø–∫–µ
                folder_options = list(set(item["folder"] for item in display_data))
                folder_filter = st.multiselect(
                    "–ü–∞–ø–∫–∞:",
                    options=folder_options,
                    default=folder_options,
                    format_func=lambda x: {
                        "normative": "üìñ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ",
                        "methodology": "üìö –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ",
                        "structured": "üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ",
                        "expertise": "üë®‚Äç‚öñÔ∏è –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ"
                    }.get(x, x)
                )
            
            with col2:
                # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É
                type_options = list(set(item["type"] for item in display_data))
                type_filter = st.multiselect(
                    "–¢–∏–ø —Ä–∞–∑–¥–µ–ª–∞:",
                    options=type_options,
                    default=type_options
                )
            
            with col3:
                # –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É
                search_text = st.text_input("–ü–æ–∏—Å–∫:", placeholder="–ü–æ –¥–æ–∫—É–º–µ–Ω—Ç—É –∏–ª–∏ —Ä–∞–∑–¥–µ–ª—É...")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        filtered_data = display_data.copy()
        
        if folder_filter:
            filtered_data = [item for item in filtered_data if item["folder"] in folder_filter]
        
        if type_filter:
            filtered_data = [item for item in filtered_data if item["type"] in type_filter]
        
        if search_text:
            search_lower = search_text.lower()
            filtered_data = [
                item for item in filtered_data
                if (search_lower in item["document_full"].lower() or
                    search_lower in item["section_full"].lower())
            ]
        
        # –°–æ–∑–¥–∞–µ–º —Ö—ç—à —Ç–µ–∫—É—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
        current_filter_hash = f"{folder_filter}_{type_filter}_{search_text}"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ö—ç—à —Ñ–∏–ª—å—Ç—Ä–æ–≤
        if st.session_state.current_filter_hash != current_filter_hash:
            st.session_state.current_filter_hash = current_filter_hash
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –¥–µ–π—Å—Ç–≤–∏—è
        with st.container():
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            
            with col_stat1:
                st.metric("–ù–∞–π–¥–µ–Ω–æ", len(filtered_data), delta=f"–∏–∑ {len(display_data)}")
            
            with col_stat2:
                selected_count = sum(1 for item in filtered_data if item["selected"])
                total_selected = sum(1 for item in display_data if item["selected"])
                st.metric("–í—ã–±—Ä–∞–Ω–æ", selected_count)
            
            with col_stat3:
                if st.button("‚úÖ –í—ã–±—Ä–∞—Ç—å –≤—Å–µ", use_container_width=True):
                    for item in filtered_data:
                        for section in db.sections:
                            if section.get("id") == item["id"]:
                                section["selected"] = True
                    st.session_state.has_unsaved_changes = True
                    st.success(f"–í—ã–±—Ä–∞–Ω–æ {len(filtered_data)}")
                    st.rerun()
            
            with col_stat4:
                if st.button("‚ùå –°–Ω—è—Ç—å –≤—Å–µ", use_container_width=True):
                    for item in filtered_data:
                        for section in db.sections:
                            if section.get("id") == item["id"]:
                                section["selected"] = False
                    st.session_state.has_unsaved_changes = True
                    st.info(f"–°–Ω—è—Ç–æ {len(filtered_data)}")
                    st.rerun()
        
        # –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ê–ó–î–ï–õ–û–í –í –ö–û–ú–ü–ê–ö–¢–ù–û–ú –§–û–†–ú–ê–¢–ï
        if filtered_data:
            changes_made = False
            
            # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ä–∞–∑–¥–µ–ª–æ–≤
            with st.container():
                for idx, item in enumerate(filtered_data):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º CSS –∫–ª–∞—Å—Å—ã
                    css_class = "section-item"
                    if item["selected"]:
                        css_class += " selected-section"
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª
                    col_check, col_content = st.columns([0.4, 11.6])
                    
                    with col_check:
                        # –ß–µ–∫–±–æ–∫—Å –¥–ª—è –≤—ã–±–æ—Ä–∞ (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π)
                        current_selected = item["selected"]
                        new_selected = st.checkbox(
                            "",
                            value=current_selected,
                            key=f"select_{item['id']}_{current_filter_hash}",
                            label_visibility="collapsed"
                        )
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
                        if new_selected != current_selected:
                            for section in db.sections:
                                if section.get("id") == item["id"]:
                                    section["selected"] = new_selected
                                    changes_made = True
                                    break
                    
                    with col_content:
                        # –ö–æ–º–ø–∞–∫—Ç–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                        st.markdown(f'<div class="{css_class}">', unsafe_allow_html=True)
                        
                        # –î–æ–∫—É–º–µ–Ω—Ç (–∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç —Å —Ö–æ—Ä–æ—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç—å—é –≤ —Ç–µ–º–Ω–æ–π —Ç–µ–º–µ)
                        folder_icon = {
                            "normative": "üìñ",
                            "methodology": "üìö",
                            "structured": "üóÇÔ∏è",
                            "expertise": "üë®‚Äç‚öñÔ∏è"
                        }.get(item["folder"], "üìÑ")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º span —Å –≤–∞–∂–Ω—ã–º–∏ —Å—Ç–∏–ª—è–º–∏ –¥–ª—è —Ç–µ–º–Ω–æ–π —Ç–µ–º—ã
                        st.markdown(
                            f'<div class="section-header">'
                            f'<span style="font-weight: 600; color: inherit;">{folder_icon} {item["document"]}</span>'
                            f'</div>', 
                            unsafe_allow_html=True
                        )
                        
                        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
                        meta_info = []
                        meta_info.append(f"–¢–∏–ø: {item['type']}")
                        meta_info.append(f"–°–ª–æ–≤: {item['words']}")
                        if item["selected"]:
                            meta_info.append("‚úÖ –í—ã–±—Ä–∞–Ω–æ")
                        
                        st.markdown(f'<div class="section-meta">{" ‚Ä¢ ".join(meta_info)}</div>', 
                                unsafe_allow_html=True)
                        
                        # –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ —Å —Ö–æ—Ä–æ—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç—å—é
                        st.markdown(
                            f'<div class="section-title">'
                            f'<span style="font-weight: 500; color: inherit;">{item["section"]}</span>'
                            f'</div>', 
                            unsafe_allow_html=True
                        )
                        
                        st.markdown('</div>', unsafe_allow_html=True)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if changes_made:
                st.session_state.has_unsaved_changes = True
            
            # –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –ø–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            st.markdown("---")
            
            with st.container():
                col_manage1, col_manage2, col_manage3 = st.columns(3)
                
                with col_manage1:
                    # –ö–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                    save_disabled = not st.session_state.has_unsaved_changes
                    
                    if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—ã–±–æ—Ä", type="primary", 
                               disabled=save_disabled, use_container_width=True):
                        db.save_database()
                        st.success("‚úÖ –í—ã–±–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
                        add_notification("–í—ã–±–æ—Ä —Ä–∞–∑–¥–µ–ª–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω", "success")
                        st.session_state.has_unsaved_changes = False
                        st.rerun()
                
                with col_manage2:
                    # –ö–Ω–æ–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è DeepSeek
                    total_selected = sum(1 for item in display_data if item["selected"])
                    create_disabled = total_selected == 0
                    
                    if st.button("ü§ñ –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª—ã", type="secondary",
                               disabled=create_disabled, use_container_width=True):
                        selected_sections = db.get_selected_sections()
                        
                        with st.spinner("–°–æ–∑–¥–∞—é —Ñ–∞–π–ª—ã..."):
                            output_dir = Path("./expert_sessions")
                            output_dir.mkdir(exist_ok=True, parents=True)
                            
                            session_dir = ExpertFileGenerator.create_prompt_file(
                                selected_sections, 
                                output_dir,
                                template_manager,
                                st.session_state.selected_template
                            )
                            
                            if session_dir:
                                st.session_state.session_dir = session_dir
                                st.session_state.files_created = True
                                
                                st.success(f"‚úÖ –§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã!")
                                add_notification("–§–∞–π–ª—ã —Å–µ—Å—Å–∏–∏ —Å–æ–∑–¥–∞–Ω—ã", "success")
                                st.rerun()
                
                with col_manage3:
                    # –°—Ç–∞—Ç—É—Å
                    if st.session_state.has_unsaved_changes:
                        st.warning("‚ö†Ô∏è –ù–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
                    else:
                        st.info("üíæ –í—Å–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        
        else:
            st.info("–ù–µ—Ç —Ä–∞–∑–¥–µ–ª–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º.")

# ==============================================
# –í–ö–õ–ê–î–ö–ê 2: –í–´–ë–û–† –®–ê–ë–õ–û–ù–ê
# ==============================================

with tab2:
    st.subheader("üéØ –í–´–ë–û–† –®–ê–ë–õ–û–ù–ê –î–õ–Ø –ò–ò")
    
    templates = template_manager.get_templates_list()
    
    if not templates:
        st.info("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤. –°–æ–∑–¥–∞–π—Ç–µ –ø–µ—Ä–≤—ã–π —à–∞–±–ª–æ–Ω.")
    else:
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π –≤—ã–±—Ä–∞–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω
        current_template = template_manager.get_template_by_id(st.session_state.selected_template)
        if current_template:
            st.markdown(f"### üìå –¢–ï–ö–£–©–ò–ô –®–ê–ë–õ–û–ù: **{current_template.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}**")
            st.markdown(f"*{current_template.get('description', '')}*")
            st.markdown("---")
        
        # –í—ã–±–æ—Ä —à–∞–±–ª–æ–Ω–∞
        st.markdown("### üìã –í–´–ë–ï–†–ò–¢–ï –®–ê–ë–õ–û–ù –û–¢–í–ï–¢–ê:")
        
        for template in templates:
            is_selected = template["id"] == st.session_state.selected_template
            
            # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫—É —à–∞–±–ª–æ–Ω–∞
            css_class = "template-card"
            if is_selected:
                css_class += " selected"
            
            with st.container():
                col1, col2 = st.columns([0.1, 0.9])
                
                with col1:
                    # –†–∞–¥–∏–æ-–∫–Ω–æ–ø–∫–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞
                    if st.button("‚úì", key=f"select_template_{template['id']}", 
                               disabled=is_selected, use_container_width=True):
                        st.session_state.selected_template = template["id"]
                        st.success(f"–í—ã–±—Ä–∞–Ω —à–∞–±–ª–æ–Ω: {template['name']}")
                        add_notification(f"–í—ã–±—Ä–∞–Ω —à–∞–±–ª–æ–Ω: {template['name']}", "info")
                        st.rerun()
                
                with col2:
                    st.markdown(f'<div class="{css_class}" onclick="document.getElementById(\'template_{template["id"]}\').click()">', 
                              unsafe_allow_html=True)
                    st.markdown(f'<div class="template-name">{template.get("name", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")}</div>', 
                              unsafe_allow_html=True)
                    st.markdown(f'<div class="template-description">{template.get("description", "")}</div>', 
                              unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
        
        # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —à–∞–±–ª–æ–Ω–∞
        st.markdown("---")
        st.markdown("### üëÅÔ∏è –ü–†–ï–î–ü–†–û–°–ú–û–¢–† –®–ê–ë–õ–û–ù–ê")
        
        if current_template:
            with st.expander("üìù –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞"):
                st.text_area("–¢–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞:", 
                           value=current_template.get("prompt", ""),
                           height=300,
                           disabled=True,
                           key=f"preview_{current_template['id']}")
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–Ω–æ–ø–æ–∫ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        if st.session_state.files_created and st.session_state.session_dir:
            st.markdown("---")
            st.markdown("##### üì• –°–ö–ê–ß–ê–¢–¨ –§–ê–ô–õ–´ –°–ï–°–°–ò–ò")
            
            session_dir = st.session_state.session_dir
            
            # –ö–æ–º–ø–∞–∫—Ç–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–Ω–æ–ø–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            col_download1, col_download2, col_download3, col_download4, col_download5 = st.columns(5)
            
            # –§–∞–π–ª all_sections.md
            all_sections_path = session_dir / "all_sections.md"
            if all_sections_path.exists():
                with col_download1:
                    with open(all_sections_path, 'r', encoding='utf-8') as f:
                        all_sections_content = f.read()
                    
                    st.download_button(
                        label="üìÑ –†–∞–∑–¥–µ–ª—ã",
                        data=all_sections_content,
                        file_name=f"all_sections.md",
                        mime="text/markdown",
                        use_container_width=True,
                        help="–í—Å–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã"
                    )
            
            # –§–∞–π–ª deepseek_prompt.txt
            prompt_path = session_dir / "deepseek_prompt.txt"
            if prompt_path.exists():
                with col_download2:
                    with open(prompt_path, 'r', encoding='utf-8') as f:
                        prompt_content = f.read()
                    
                    st.download_button(
                        label="ü§ñ –ü—Ä–æ–º—Ç",
                        data=prompt_content,
                        file_name=f"deepseek_prompt.txt",
                        mime="text/plain",
                        use_container_width=True,
                        help="–ü—Ä–æ–º—Ç –¥–ª—è DeepSeek"
                    )
            
            # –§–∞–π–ª report.txt
            report_path = session_dir / "report.txt"
            if report_path.exists():
                with col_download3:
                    with open(report_path, 'r', encoding='utf-8') as f:
                        report_content = f.read()
                    
                    st.download_button(
                        label="üìä –û—Ç—á–µ—Ç",
                        data=report_content,
                        file_name=f"report.txt",
                        mime="text/plain",
                        use_container_width=True,
                        help="–û—Ç—á–µ—Ç –ø–æ —Å–µ—Å—Å–∏–∏"
                    )
            
            # –§–∞–π–ª sections_data.json
            json_path = session_dir / "sections_data.json"
            if json_path.exists():
                with col_download4:
                    with open(json_path, 'r', encoding='utf-8') as f:
                        json_content = f.read()
                    
                    st.download_button(
                        label="üìÅ JSON",
                        data=json_content,
                        file_name=f"sections_data.json",
                        mime="application/json",
                        use_container_width=True,
                        help="–î–∞–Ω–Ω—ã–µ –≤ JSON"
                    )
            
            # –§–∞–π–ª template_info.json
            template_path = session_dir / "template_info.json"
            if template_path.exists():
                with col_download5:
                    with open(template_path, 'r', encoding='utf-8') as f:
                        template_content = f.read()
                    
                    st.download_button(
                        label="üéØ –®–∞–±–ª–æ–Ω",
                        data=template_content,
                        file_name=f"template_info.json",
                        mime="application/json",
                        use_container_width=True,
                        help="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —à–∞–±–ª–æ–Ω–µ"
                    )

# ==============================================
# –í–ö–õ–ê–î–ö–ê 3: –ù–ê–°–¢–†–û–ô–ö–ò
# ==============================================

with tab3:
    st.subheader("‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò")
    
    st.markdown("### üìÇ –ü–£–¢–ò –ö –ü–ê–ü–ö–ê–ú")
    
    for folder_name, folder_path in CONFIG["folders"].items():
        st.text_input(
            f"–ü–∞–ø–∫–∞ {folder_name}:",
            value=folder_path,
            key=f"path_{folder_name}",
            disabled=True
        )
    
    st.markdown("---")
    
    if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", type="secondary"):
        st.info("–í –¥–µ–º–æ-–≤–µ—Ä—Å–∏–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è")

# ==============================================
# –í–ö–õ–ê–î–ö–ê 4: –ê–î–ú–ò–ù–ò–°–¢–†–ò–†–û–í–ê–ù–ò–ï
# ==============================================

with tab4:
    st.subheader("üõ†Ô∏è –ê–î–ú–ò–ù–ò–°–¢–†–ò–†–û–í–ê–ù–ò–ï")
    
    col_admin1, col_admin2 = st.columns(2)
    
    with col_admin1:
        # –ë–ª–æ–∫ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –±–∞–∑–æ–π
        st.markdown("### üóëÔ∏è –û–ü–ï–†–ê–¶–ò–ò –° –ë–ê–ó–û–ô")
        
        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        if st.button("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–∞–ø–∫–∏", type="primary", use_container_width=True):
            with st.spinner("–°–∫–∞–Ω–∏—Ä—É—é –ø–∞–ø–∫–∏..."):
                db.scan_and_build_database()
                st.success("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")
                add_notification("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∞", "success")
                st.session_state.has_unsaved_changes = False
                st.rerun()
        
        # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –±–∞–∑—ã
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É", type="secondary", use_container_width=True):
            st.warning("–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –æ—á–∏—Å—Ç–∏—Ç –≤—Å—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!")
            if st.checkbox("–Ø –ø–æ–Ω–∏–º–∞—é –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è"):
                db.sections = []
                db.metadata = {
                    "created_at": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                    "total_sections": 0,
                    "total_documents": 0,
                    "by_folder": {}
                }
                db.save_database()
                st.success("–ë–∞–∑–∞ –æ—á–∏—â–µ–Ω–∞!")
                st.session_state.has_unsaved_changes = False
                st.rerun()
    
    with col_admin2:
        # –ë–ª–æ–∫ –∏–º–ø–æ—Ä—Ç–∞/—ç–∫—Å–ø–æ—Ä—Ç–∞
        st.markdown("### üì§ –ò–ú–ü–û–†–¢/–≠–ö–°–ü–û–†–¢")
        
        # –ò–º–ø–æ—Ä—Ç
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –±–∞–∑—ã (JSON):",
            type=['json'],
            key="import_uploader"
        )
        
        if uploaded_file is not None:
            try:
                import_data = json.load(uploaded_file)
                if st.button("üì• –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", type="primary"):
                    if 'sections' in import_data and 'metadata' in import_data:
                        db.sections = import_data['sections']
                        db.metadata = import_data['metadata']
                        db.save_database()
                        st.success("–ë–∞–∑–∞ —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞!")
                        add_notification(f"–ë–∞–∑–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑ {uploaded_file.name}", "success")
                        st.session_state.has_unsaved_changes = False
                        st.rerun()
                    else:
                        st.error("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –±–∞–∑—ã")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç
        if st.button("üì§ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É", type="secondary", use_container_width=True):
            export_data = {
                "sections": db.sections,
                "metadata": db.metadata
            }
            
            export_json = json.dumps(export_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –±–∞–∑—É (JSON)",
                data=export_json,
                file_name=f"database_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
    
    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞–º–∏
    st.markdown("---")
    st.markdown("### üéØ –£–ü–†–ê–í–õ–ï–ù–ò–ï –®–ê–ë–õ–û–ù–ê–ú–ò")
    
    col_template1, col_template2 = st.columns(2)
    
    with col_template1:
        # –ü—Ä–æ—Å–º–æ—Ç—Ä –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–æ–≤
        st.markdown("##### üìù –†–ï–î–ê–ö–¢–ò–†–û–í–ê–¢–¨ –®–ê–ë–õ–û–ù–´")
        
        templates = template_manager.get_templates_list()
        
        for template in templates:
            with st.expander(f"‚úèÔ∏è {template.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}", expanded=False):
                new_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ:", 
                                       value=template.get('name', ''),
                                       key=f"name_{template['id']}")
                
                new_description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ:",
                                             value=template.get('description', ''),
                                             key=f"desc_{template['id']}")
                
                new_prompt = st.text_area("–¢–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞:",
                                        value=template.get('prompt', ''),
                                        height=200,
                                        key=f"prompt_{template['id']}")
                
                if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key=f"save_{template['id']}"):
                    # –û–±–Ω–æ–≤–ª—è–µ–º —à–∞–±–ª–æ–Ω
                    template['name'] = new_name
                    template['description'] = new_description
                    template['prompt'] = new_prompt
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                    template_manager.update_templates(template_manager.templates)
                    st.success(f"–®–∞–±–ª–æ–Ω '{new_name}' –æ–±–Ω–æ–≤–ª–µ–Ω!")
                    add_notification(f"–®–∞–±–ª–æ–Ω '{new_name}' –æ–±–Ω–æ–≤–ª–µ–Ω", "success")
                    st.rerun()
    
    with col_template2:
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —à–∞–±–ª–æ–Ω–∞
        st.markdown("##### ‚ûï –°–û–ó–î–ê–¢–¨ –ù–û–í–´–ô –®–ê–ë–õ–û–ù")
        
        with st.form("new_template_form"):
            new_template_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —à–∞–±–ª–æ–Ω–∞:", 
                                            placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
            
            new_template_desc = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞:",
                                           placeholder="–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ü–µ–ª–∏ —à–∞–±–ª–æ–Ω–∞")
            
            new_template_prompt = st.text_area("–¢–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞:",
                                             placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –ø—Ä–æ–º—Ç–∞ –¥–ª—è –ò–ò...",
                                             height=250)
            
            submit_btn = st.form_submit_button("‚ûï –°–æ–∑–¥–∞—Ç—å —à–∞–±–ª–æ–Ω", type="primary")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º—ã –≤—ã–Ω–µ—Å–µ–Ω–∞ –í–ù–ï —Ñ–æ—Ä–º—ã
        if submit_btn:
            if new_template_name and new_template_prompt:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —à–∞–±–ª–æ–Ω
                new_template = {
                    "id": f"template_{uuid.uuid4().hex[:8]}",
                    "name": new_template_name,
                    "description": new_template_desc,
                    "prompt": new_template_prompt
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ —à–∞–±–ª–æ–Ω–æ–≤
                templates = template_manager.get_templates_list()
                templates.append(new_template)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —à–∞–±–ª–æ–Ω—ã
                template_manager.templates["templates"] = templates
                template_manager.update_templates(template_manager.templates)
                
                st.success(f"–®–∞–±–ª–æ–Ω '{new_template_name}' —Å–æ–∑–¥–∞–Ω!")
                add_notification(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —à–∞–±–ª–æ–Ω: {new_template_name}", "success")
                st.rerun()
            else:
                st.error("–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ç–µ–∫—Å—Ç —à–∞–±–ª–æ–Ω–∞")
    
    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤ - –í–ù–ï —Ñ–æ—Ä–º—ã, –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫
    st.markdown("---")
    st.markdown("### üîÑ –ü–ï–†–ï–ó–ê–ì–†–£–ó–ö–ê –®–ê–ë–õ–û–ù–û–í")
    
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —à–∞–±–ª–æ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞", type="secondary", use_container_width=True):
        template_manager.reload_templates()
        st.success("–®–∞–±–ª–æ–Ω—ã –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")
        add_notification("–®–∞–±–ª–æ–Ω—ã –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞", "success")
        st.rerun()

# ==============================================
# –°–ê–ô–î–ë–ê–†
# ==============================================

with st.sidebar:
    st.header("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.metric("–í—Å–µ–≥–æ —Ä–∞–∑–¥–µ–ª–æ–≤", db.metadata.get("total_sections", 0))
    st.metric("–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤", db.metadata.get("total_documents", 0))
    
    # –ü–æ–¥—Å—á–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö
    selected_count = sum(1 for section in db.sections if section.get("selected", False))
    st.metric("–í—ã–±—Ä–∞–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤", selected_count)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —à–∞–±–ª–æ–Ω–µ
    current_template = template_manager.get_template_by_id(st.session_state.selected_template)
    if current_template:
        st.markdown("---")
        st.header("üéØ –®–ê–ë–õ–û–ù")
        st.markdown(f"**{current_template.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}**")
        st.caption(current_template.get('description', ''))
    
    if db.metadata.get("last_updated"):
        st.caption(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ: {db.metadata['last_updated'][:10]}")
    
    st.markdown("---")
    st.header("‚ö° –ë–´–°–¢–†–´–ï –î–ï–ô–°–¢–í–ò–Ø")
    
    # –ö–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
    if st.session_state.has_unsaved_changes:
        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—ã–±–æ—Ä", type="primary", use_container_width=True):
            db.save_database()
            st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")
            st.session_state.has_unsaved_changes = False
            st.rerun()
    
    # –ö–Ω–æ–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–º—Ç–∞
    if selected_count > 0:
        if st.button("ü§ñ –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª—ã —Å–µ—Å—Å–∏–∏", type="secondary", use_container_width=True):
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å –∫–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            selected_sections = db.get_selected_sections()
            with st.spinner("–°–æ–∑–¥–∞—é —Ñ–∞–π–ª—ã..."):
                output_dir = Path("./expert_sessions")
                output_dir.mkdir(exist_ok=True, parents=True)
                session_dir = ExpertFileGenerator.create_prompt_file(
                    selected_sections, 
                    output_dir,
                    template_manager,
                    st.session_state.selected_template
                )
                if session_dir:
                    st.session_state.session_dir = session_dir
                    st.session_state.files_created = True
                    st.success("–§–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã!")
                    add_notification("–§–∞–π–ª—ã —Å–µ—Å—Å–∏–∏ —Å–æ–∑–¥–∞–Ω—ã", "success")
                    st.rerun()
    else:
        st.caption("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤")
    
    st.markdown("---")
    st.header("üîî –£–í–ï–î–û–ú–õ–ï–ù–ò–Ø")
    
    if 'notifications' in st.session_state and st.session_state.notifications:
        for notification in reversed(st.session_state.notifications[-3:]):
            icon = {
                "info": "‚ÑπÔ∏è",
                "success": "‚úÖ",
                "warning": "‚ö†Ô∏è",
                "error": "‚ùå"
            }.get(notification["type"], "‚ÑπÔ∏è")
            
            st.caption(f"{icon} {notification['time']}: {notification['message']}")
        
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è", use_container_width=True):
            st.session_state.notifications = []
            st.rerun()
    else:
        st.caption("–ù–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")